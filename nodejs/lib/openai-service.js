import fs from "fs";
import OpenAI from "openai";
import dotenv from "dotenv";
import path from "path";
import {fileURLToPath} from "url";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
dotenv.config({path: path.join(__dirname, '..', '.env')});

const openai = new OpenAI({apiKey: process.env.OPENAI_API_KEY});

const SYSTEM_PROMPT = `
Ð¢Ñ‹ Ð² Ñ€ÐµÐ¶Ð¸Ð¼Ðµ Ð¾Ñ‚Ð»Ð°Ð´ÐºÐ¸.
Ð¢Ñ‹ â€” Ð¸Ð½ÑÐ¿ÐµÐºÑ‚Ð¾Ñ€, Ð¿Ñ€Ð¾Ð²Ð¾Ð´ÑÑ‰Ð¸Ð¹ ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð½Ð° ÐšÐ°Ñ€Ñ‚Ñƒ Ð¿Ð¾Ð»ÑÐºÐ°.
Ð“Ð¾Ð²Ð¾Ñ€Ð¸ÑˆÑŒ Ð²ÐµÐ¶Ð»Ð¸Ð²Ð¾, Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»ÑŒÐ½Ð¾ Ð¸ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾, ÐºÐ°Ðº Ð³Ð¾ÑÑƒÐ´Ð°Ñ€ÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ ÑÐ»ÑƒÐ¶Ð°Ñ‰Ð¸Ð¹, Ð½Ð¾ Ð¾ÑÑ‚Ð°Ñ‘ÑˆÑŒÑÑ Ð´Ð¾Ð±Ñ€Ð¾Ð¶ÐµÐ»Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼ Ð¸ Ñ‚ÐµÑ€Ð¿ÐµÐ»Ð¸Ð²Ñ‹Ð¼.
Ð¢Ð²Ð¾Ñ Ñ†ÐµÐ»ÑŒ â€” Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Ð·Ð½Ð°Ð½Ð¸Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¾ ÐŸÐ¾Ð»ÑŒÑˆÐµ Ð¸ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ ÐµÐ¼Ñƒ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ñ‚ÑŒÑÑ Ðº Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼Ñƒ ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸ÑŽ.

ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹:
- Ð’ÑÐµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ get_next_question().
  ÐžÐ½Ð° Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚:
    - question â€” Ñ‚ÐµÐºÑÑ‚ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ° (ÐµÐ³Ð¾ Ð½ÑƒÐ¶Ð½Ð¾ Ð¾Ð·Ð²ÑƒÑ‡Ð¸Ñ‚ÑŒ);
    - options â€” Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ñ‹ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² (ÐÐ• Ð¿Ñ€Ð¾Ð¸Ð·Ð½Ð¾ÑÐ¸Ñ‚ÑŒ);
    - question_answer_id â€” ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ID Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°.
- ÐšÐ¾Ð³Ð´Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÐµÑ‚ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾, Ð²Ñ‹Ð·Ñ‹Ð²Ð°Ð¹ save_quiz_response(question_answer_id) Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°.

Ð›Ð¾Ð³Ð¸ÐºÐ° Ð¿Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸Ñ:
1. ÐŸÐµÑ€Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ:
   Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ð¾Ð·Ð´Ð¾Ñ€Ð¾Ð²Ð°Ð¹ÑÑ Ð¸ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²ÑŒÑÑ.
   ÐÐµ Ð²Ñ‹Ð·Ñ‹Ð²Ð°Ð¹ get_next_question() Ð¸ Ð½Ðµ Ð·Ð°Ð´Ð°Ð²Ð°Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ, Ð¿Ð¾ÐºÐ° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð½Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ñ‚.
   ÐŸÑ€Ð¸Ð¼ÐµÑ€: "DzieÅ„ dobry. Jestem inspektorem, ktÃ³ry przeprowadzi z tobÄ… krÃ³tkÄ… rozmowÄ™ w jÄ™zyku polskim. Gotowy?"

2. ÐŸÐ¾ÑÐ»Ðµ ÑÐ¾Ð³Ð»Ð°ÑÐ¸Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ:
   - Ð’Ñ‹Ð·Ð¾Ð²Ð¸ get_next_question().
   - ÐžÐ·Ð²ÑƒÑ‡ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ‚ÐµÐºÑÑ‚ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ° (Ð±ÐµÐ· Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð¾Ð²).

3. ÐŸÐ¾ÑÐ»Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ:
   - Ð•ÑÐ»Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¹:
       Ð¡ÐºÐ°Ð¶Ð¸: "Dobrze. Poprawna odpowiedÅº."
       Ð’Ñ‹Ð·Ð¾Ð²Ð¸ save_quiz_response(question_answer_id).
   - Ð•ÑÐ»Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¿Ð¾Ñ‡Ñ‚Ð¸ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¹:
       Ð¡ÐºÐ°Ð¶Ð¸: "Blisko. Ale poprawna odpowiedÅº brzmi..."
   - Ð•ÑÐ»Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚ Ð½ÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹:
       Ð¡ÐºÐ°Ð¶Ð¸: "Niepoprawnie. PrawidÅ‚owa odpowiedÅº to..."
   - Ð—Ð°Ñ‚ÐµÐ¼ Ð²Ñ‹Ð·Ð¾Ð²Ð¸ get_next_question() Ð´Ð»Ñ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°.

4. Ð¢Ð¾Ð½ Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ:
   - Ð¡Ñ‚Ð¸Ð»ÑŒ Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ð¹, Ð½Ð¾ Ð´Ð¾Ð±Ñ€Ð¾Ð¶ÐµÐ»Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹.
   - Ð˜Ð·Ð±ÐµÐ³Ð°Ð¹ ÑŽÐ¼Ð¾Ñ€Ð°.
   - ÐœÐ¾Ð¶Ð½Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ñ„Ñ€Ð°Ð·Ñ‹ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸:
       "ProszÄ™ siÄ™ nie stresowaÄ‡."
       "To tylko Ä‡wiczenie przed prawdziwÄ… rozmowÄ…."
   - Ð•ÑÐ»Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð¼Ð¾Ð»Ñ‡Ð¸Ñ‚:
       "Czy chcesz, Å¼ebym powtÃ³rzyÅ‚ pytanie?"

5. Ð—Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ:
   ÐšÐ¾Ð³Ð´Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð±Ð¾Ð»ÑŒÑˆÐµ Ð½ÐµÑ‚, ÑÐºÐ°Ð¶Ð¸:
   "DziÄ™kujÄ™. To wszystko na dziÅ›. Å»yczÄ™ powodzenia w dalszej nauce jÄ™zyka polskiego."

ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°:
ðŸ¤–: DzieÅ„ dobry. Jestem inspektorem, ktÃ³ry przeprowadzi z tobÄ… krÃ³tkÄ… rozmowÄ™ w jÄ™zyku polskim. Gotowy?
ðŸ‘¤: Tak.
ðŸ¤–: Dobrze. Pierwsze pytanie: kto byÅ‚ pierwszym krÃ³lem Polski?
ðŸ‘¤: Mieszko pierwszy.
ðŸ¤–: Niepoprawnie. Mieszko I byÅ‚ ksiÄ™ciem. Pierwszym krÃ³lem byÅ‚ BolesÅ‚aw Chrobry. NastÄ™pne pytanie...
(Ð²Ñ‹Ð·Ð¾Ð² get_next_question())
ðŸ‘¤: [Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚]
ðŸ¤–: Dobrze. Poprawna odpowiedÅº.
(Ð²Ñ‹Ð·Ð¾Ð² save_quiz_response(question_answer_id))
`;


export async function transcribeAudio(filePath) {
    const stt = await openai.audio.transcriptions.create({
        model: "gpt-4o-mini-transcribe",
        file: fs.createReadStream(filePath),
        language: 'pl'
    });

    return stt.text;
}

export async function generateChatResponse(userText, tools = null, conversationId = null) {
    const options = {
        model: "gpt-4o-mini",
        'parallel_tool_calls': true,
        'tool_choice': 'auto',
        'instructions': SYSTEM_PROMPT,
        'conversation': conversationId,
        input: userText,
    };

    // Add tools if provided (convert to responses API format)
    if (tools) {
        options.tools = tools.map(tool => ({
            type: "function",
            name: tool.function.name,
            description: tool.function.description,
            parameters: tool.function.parameters,
            strict: tool.function.strict
        }));
        options.tool_choice = "auto";
    }

    const response = await openai.responses.create(options);

    // Extract text content and tool calls from output items
    let textContent = null;
    const toolCalls = [];
    const outputItems = response.output || [];

    for (const item of outputItems) {
        // Extract text from message items
        if (item.content && Array.isArray(item.content)) {
            const textParts = item.content
                .filter(c => c.type === 'output_text')
                .map(c => c.text);
            if (textParts.length > 0) {
                textContent = textParts.join('\n');
            }
        }

        // Extract function calls
        if (item.type === 'function_call') {
            const args = item['arguments'];
            toolCalls.push({
                id: item.call_id,
                type: 'function',
                function: {
                    name: item.name,
                    arguments: typeof args === 'string' ? args : JSON.stringify(args)
                }
            });
        }
    }

    // Convert response format to match chat completions format
    return {
        content: textContent,
        tool_calls: toolCalls.length > 0 ? toolCalls : undefined
    };
}

export async function generateChatResponseForTools(toolResults, conversationId = null) {
    let input = [];
    for (const [call_id, result] of Object.entries(toolResults)) {
        const toolOutput = {
            type: 'function_call_output',
            call_id,
            output: JSON.stringify(result),
        };

        input.push(toolOutput);
    }

    const payload = {
        'instructions': SYSTEM_PROMPT,
        'input': input,
        model: "gpt-4o-mini",
        'conversation': conversationId
    };
    // console.log('payload', payload);

    const response = await openai.responses.create(payload);

    // console.log('response', response);

    // Convert response format to match chat completions format
    return response.output_text;
}

export async function generateSpeech(text, voice = "verse") {
    const speech = await openai.audio.speech.create({
        model: "gpt-4o-mini-tts",
        voice: voice,
        input: text,
        response_format: "mp3",
    });

    const buffer = Buffer.from(await speech.arrayBuffer());

    return buffer;
}
