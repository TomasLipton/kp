import fs from "fs";
import OpenAI from "openai";
import dotenv from "dotenv";
import path from "path";
import {fileURLToPath} from "url";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
dotenv.config({path: path.join(__dirname, '..', '.env')});

const openai = new OpenAI({apiKey: process.env.OPENAI_API_KEY});

const SYSTEM_PROMPT = `
ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚ Ð´Ð»Ñ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð³Ð¾ Ñ‡Ð°Ñ‚-Ð±Ð¾Ñ‚Ð° "Ð˜Ð½ÑÐ¿ÐµÐºÑ‚Ð¾Ñ€ Ð¿Ð¾ ÐšÐ°Ñ€Ñ‚Ðµ ÐŸÐ¾Ð»ÑÐºÐ°"

Ð¢Ñ‹ â€” Ð¸Ð½ÑÐ¿ÐµÐºÑ‚Ð¾Ñ€, Ð¿Ñ€Ð¾Ð²Ð¾Ð´ÑÑ‰Ð¸Ð¹ ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð½Ð° ÐšÐ°Ñ€Ñ‚Ñƒ Ð¿Ð¾Ð»ÑÐºÐ°.
Ð“Ð¾Ð²Ð¾Ñ€Ð¸ÑˆÑŒ Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¼ ÐºÐ°Ðº Ð´Ð¾Ð±Ñ€Ð¾Ð¶ÐµÐ»Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹, Ð½Ð¾ ÑÑ‚Ñ€Ð¾Ð³Ð¸Ð¹ Ð³Ð¾ÑÑƒÐ´Ð°Ñ€ÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ ÑÐ»ÑƒÐ¶Ð°Ñ‰Ð¸Ð¹: Ð²ÐµÐ¶Ð»Ð¸Ð²Ð¾, ÑÐ¿Ð¾ÐºÐ¾Ð¹Ð½Ð¾, Ñ Ð»Ñ‘Ð³ÐºÐ¾Ð¹ Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒÑŽ.
Ð¢Ñ‹ ÑÐ»ÐµÐ´Ð¸ÑˆÑŒ Ð·Ð° ÐºÑƒÐ»ÑŒÑ‚ÑƒÑ€Ð¾Ð¹ Ñ€ÐµÑ‡Ð¸ Ð¸ Ð°ÐºÐºÑƒÑ€Ð°Ñ‚Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð², Ð½Ð¾ ÑÑ‚Ð°Ñ€Ð°ÐµÑˆÑŒÑÑ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ Ð¸ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ, ÐµÑÐ»Ð¸ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐº Ð²Ð¾Ð»Ð½ÑƒÐµÑ‚ÑÑ.

ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹:

Ð’Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð±ÐµÑ€ÑƒÑ‚ÑÑ Ð¸Ð· Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ get_next_question().

ÐšÐ°Ð¶Ð´Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ñ‚ÐµÐºÑÑ‚ Ð¸ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ñ‹ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð², Ð½Ð¾ Ñ‚Ñ‹ Ð½Ðµ Ð¿Ñ€Ð¾Ð¸Ð·Ð½Ð¾ÑÐ¸ÑˆÑŒ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ñ‹ â€” Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑˆÑŒ Ð¸Ñ… Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸.

ÐžÐ±Ñ‰ÐµÐ½Ð¸Ðµ Ð²ÐµÐ´Ñ‘Ñ‚ÑÑ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð¼.

ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ ÑÐ·Ñ‹Ðº â€” Ð¿Ð¾Ð»ÑŒÑÐºÐ¸Ð¹, Ð½Ð¾ ÐµÑÐ»Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ ÑÐ²Ð½Ð¾ Ð½Ðµ Ð¿Ð¾Ð½Ð¸Ð¼Ð°ÐµÑ‚, Ð¼Ð¾Ð¶ÐµÑˆÑŒ ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð¾Ð±ÑŠÑÑÐ½Ð¸Ñ‚ÑŒ Ð¿Ð¾-Ñ€ÑƒÑÑÐºÐ¸.

ÐŸÐ¾Ñ€ÑÐ´Ð¾Ðº Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ð¹:

ðŸ”¹ ÐŸÐµÑ€Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ:
ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð¿Ð¾Ð·Ð´Ð¾Ñ€Ð¾Ð²Ð°Ð¹ÑÑ Ð¸ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²ÑŒÑÑ:

â€žDzieÅ„ dobry. Jestem inspektorem, ktÃ³ry przeprowadzi z tobÄ… krÃ³tkÄ… rozmowÄ™ w jÄ™zyku polskim. Gotowy?â€
ÐÐµ Ð·Ð°Ð´Ð°Ð²Ð°Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¸ Ð½Ðµ Ð²Ñ‹Ð·Ñ‹Ð²Ð°Ð¹ get_next_question() ÑÑ€Ð°Ð·Ñƒ. Ð”Ð¾Ð¶Ð´Ð¸ÑÑŒ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ.

ðŸ”¹ Ð”Ð°Ð»ÑŒÐ½ÐµÐ¹ÑˆÐ¸Ðµ ÑˆÐ°Ð³Ð¸:

ÐŸÐ¾ÑÐ»Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Â«takÂ» Ð¸Ð»Ð¸ Ð´Ñ€ÑƒÐ³Ð¾Ð³Ð¾ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ â€” Ð²Ñ‹Ð·Ñ‹Ð²Ð°Ð¹ get_next_question() Ð¸ Ð·Ð°Ð´Ð°Ð¹ Ð¿ÐµÑ€Ð²Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ.

ÐžÐ·Ð²ÑƒÑ‡Ð¸Ð²Ð°Ð¹ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÑÐ°Ð¼ Ð²Ð¾Ð¿Ñ€Ð¾Ñ (Ð±ÐµÐ· Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð¾Ð²).

ÐŸÐ¾ÑÐ»Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ:

Ð¡Ñ€Ð°Ð²Ð½Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚ Ñ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¼ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð¾Ð¼.

ÐžÑ‚Ð²ÐµÑ‚ÑŒ ÑÑ‚Ñ€Ð¾Ð³Ð¾, Ð½Ð¾ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾:

âœ… Ð•ÑÐ»Ð¸ Ð²ÐµÑ€Ð½Ð¾ â†’ â€žDobrze. Poprawna odpowiedÅº.â€

âš ï¸ Ð•ÑÐ»Ð¸ Ð¿Ð¾Ñ‡Ñ‚Ð¸ â†’ â€žBlisko. Ale poprawna odpowiedÅº brzmiâ€¦â€

âŒ Ð•ÑÐ»Ð¸ Ð½ÐµÐ²ÐµÑ€Ð½Ð¾ â†’ â€žNiepoprawnie. PrawidÅ‚owa odpowiedÅº toâ€¦â€

ÐŸÐ¾ÑÐ»Ðµ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ñ â€” Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð¸ Ðº ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ¼Ñƒ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑƒ (get_next_question()).

ðŸ”¹ Ð¢Ð¾Ð½ Ð¸ ÑÑ‚Ð¸Ð»ÑŒ:

Ð“Ð¾Ð²Ð¾Ñ€Ð¸ ÑÐ¿Ð¾ÐºÐ¾Ð¹Ð½Ð¾, ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾, Ð±ÐµÐ· ÑˆÑƒÑ‚Ð¾Ðº, Ð½Ð¾ Ð½Ðµ Ñ…Ð¾Ð»Ð¾Ð´Ð½Ð¾.

Ð˜Ð½Ð¾Ð³Ð´Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ðµ Ñ„Ñ€Ð°Ð·Ñ‹ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸ (â€œProszÄ™ siÄ™ nie stresowaÄ‡.â€, â€œTo tylko Ä‡wiczenie.â€).

Ð•ÑÐ»Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð·Ð°Ð¿ÑƒÑ‚Ð°Ð»ÑÑ Ð¸Ð»Ð¸ Ð´Ð¾Ð»Ð³Ð¾ Ð¼Ð¾Ð»Ñ‡Ð¸Ñ‚ â€” Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒ (â€œCzy chcesz, Å¼ebym powtÃ³rzyÅ‚ pytanie?â€).

Ð—Ð°Ð²ÐµÑ€ÑˆÐ¸ Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾:

â€žDziÄ™kujÄ™. To wszystko na dziÅ›. Å»yczÄ™ powodzenia w dalszej nauce jÄ™zyka polskiego.â€
`.trim();

export async function transcribeAudio(filePath) {
    const stt = await openai.audio.transcriptions.create({
        model: "gpt-4o-mini-transcribe",
        file: fs.createReadStream(filePath),
    });

    return stt.text;
}

export async function generateChatResponse(userText, tools = null, conversationId = null) {
    const options = {
        model: "gpt-4o-mini",
        'parallel_tool_calls': true,
        'tool_choice': 'auto',
        'instructions': SYSTEM_PROMPT,
        'conversation': conversationId,
        input: userText,
    };

    // Add tools if provided (convert to responses API format)
    if (tools) {
        options.tools = tools.map(tool => ({
            type: "function",
            name: tool.function.name,
            description: tool.function.description,
            parameters: tool.function.parameters,
            strict: tool.function.strict
        }));
        options.tool_choice = "auto";
    }

    const response = await openai.responses.create(options);

    // Extract text content and tool calls from output items
    let textContent = null;
    const toolCalls = [];
    const outputItems = response.output || [];

    for (const item of outputItems) {
        // Extract text from message items
        if (item.content && Array.isArray(item.content)) {
            const textParts = item.content
                .filter(c => c.type === 'output_text')
                .map(c => c.text);
            if (textParts.length > 0) {
                textContent = textParts.join('\n');
            }
        }

        // Extract function calls
        if (item.type === 'function_call') {
            const args = item['arguments'];
            toolCalls.push({
                id: item.call_id,
                type: 'function',
                function: {
                    name: item.name,
                    arguments: typeof args === 'string' ? args : JSON.stringify(args)
                }
            });
        }
    }

    // Convert response format to match chat completions format
    return {
        content: textContent,
        tool_calls: toolCalls.length > 0 ? toolCalls : undefined
    };
}

export async function generateChatResponseForTools(toolResults, conversationId = null) {
    let input = [];
    for (const [call_id, result] of Object.entries(toolResults)) {
        const toolOutput = {
            type: 'function_call_output',
            call_id,
            output: JSON.stringify(result),
        };

        input.push(toolOutput);
    }

    const payload = {
        'instructions': SYSTEM_PROMPT,
        'input': input,
        model: "gpt-4o-mini",
        'conversation': conversationId
    };
    // console.log('payload', payload);

    const response = await openai.responses.create(payload);

    // console.log('response', response);

    // Convert response format to match chat completions format
    return response.output_text;
}

export async function generateSpeech(text, voice = "verse") {
    const speech = await openai.audio.speech.create({
        model: "gpt-4o-mini-tts",
        voice: voice,
        input: text,
        response_format: "mp3",
    });

    const buffer = Buffer.from(await speech.arrayBuffer());

    return buffer;
}
